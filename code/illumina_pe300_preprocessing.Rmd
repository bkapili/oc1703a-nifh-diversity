---
title: "Preprocessing raw Illumina MiSeq PE300 reads"
author: "Bennett J Kapili"
email: "kapili@stanford.edu"
date: "12/2/2021"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## R Markdown

This is an R Markdown document. Markdown is a simple formatting syntax for authoring HTML, PDF, and MS Word documents. For more details on using R Markdown see <http://rmarkdown.rstudio.com>.


# Step 0: Prerequisite installations and downloads

Create conda environment and install R (v.4.1.1), fastqc (v.0.11.9), cutadapt (v.3.5), prinseq (v.0.20.4), and FIGARO (v.1.1.2).
```{bash install software}
# Load modules
ml contribs
ml poldrack
ml anaconda

# Create conda environment
conda config --add channels conda-forge
conda config --add channels bioconda
conda create --prefix /scratch/users/kapili/oc1703a_nifh_diversity
conda activate /scratch/users/kapili/oc1703a_nifh_diversity

# Install preprocessing software
conda install -c bioconda fastqc=0.11.9
conda install -c bioconda cutadapt=3.5
conda install -c bioconda prinseq=0.20.4
conda install -c bioconda figaro=1.1.2

# Install R
conda install -c conda-forge r-base=4.1.1
```

Download raw Illumina MiSeq (PE300) data from SLIMS server.
```{bash download raw data}
# Change directory
DIRPATH=$(echo "$SCRATCH/oc1703a-nifh-diversity")

# Make data subdirectories
eval cd $DIRPATH
mkdir -p ./data/raw && cd ./data/raw

# Download data from SLIMS
wget -r -nH -nc -A "DL13_OC17*" --cut-dirs 5    "http://slimsdata.genomecenter.ucdavis.edu/Data/by0xe2e70/210830_M00384_0012_MS3086631-600V3/Unaligned/Project_ADAS_Dekas13_MCRA_NIFH/"

wget -r -nH -nc -A "DL13_MOCK*" --cut-dirs 5    "http://slimsdata.genomecenter.ucdavis.edu/Data/by0xe2e70/210830_M00384_0012_MS3086631-600V3/Unaligned/Project_ADAS_Dekas13_MCRA_NIFH/"

wget -r -nH -nc -A "DL13_BLAN*" --cut-dirs 5    "http://slimsdata.genomecenter.ucdavis.edu/Data/by0xe2e70/210830_M00384_0012_MS3086631-600V3/Unaligned/Project_ADAS_Dekas13_MCRA_NIFH/"

# Unzip (req'd for prinseq)
gzip -d *.fastq.gz
```


# Step 1: Trim primers

Use fastqc (v.0.11.9) to inspect sample quality scores.
```{bash check quality scores}
# Run fastqc
fastqc ./*.fastq

# Move to new directory
mkdir ./fastqc && mv ./*_fastqc* ./fastqc
```

Trim mehtaF/mehtaR primer sequences using cutadapt (v.3.5).
```{bash run cutadapt}
# Create new directory
mkdir ../cutadapt; cd ../cutadapt

# Create file of sample names to loop through
ls ../raw/*.fastq | sed 's/_R1_001.fastq//' | sed 's/_R2_001.fastq//' | sed 's/.*\///' | uniq > sample_names.txt

# Set read length filter
EXPECTED_LEN=273

# Loop through samples running cutadapt and print to log
for f in `cat sample_names.txt`; do
  cutadapt \
    --report=minimal \
    -g GGHAARGGHGGHATHGGNAARTC \
    -G GGCATNGCRAANCCVCCRCANAC \
    --discard-untrimmed \
    --max-n=0 \
    --match-read-wildcards \
    -e 0.1 \
    -m $EXPECTED_LEN -M $EXPECTED_LEN \
    -o "$f"_R1_001_CUTADAPT.fastq \
    -p "$f"_R2_001_CUTADAPT.fastq \
    ../raw/"$f"_R1_001.fastq ../raw/"$f"_R2_001.fastq > tmp.txt
  
  sed -i '1 s/^/sample\t/' tmp.txt
  sed -i "2 s/^/$f\t/" tmp.txt
  
  cat tmp.txt >> cutadapt_log.txt; done
  
# Remove tmp file
rm tmp.txt
```

Add percent reads written column to cutadapt log.
```{r clean cutadapt log}
# Start R session
R

# Required packages
packages <- c("dplyr", "tidyr")

# Install missing packages
installed_packages <- packages %in% rownames(installed.packages())
if (any(installed_packages == FALSE)) {
  install.packages(packages[!installed_packages])
}

# Load packages
library(dplyr)

# Add percent reads written column
df <- read.table(file = "./cutadapt_log.txt", sep = "\t", header = TRUE) %>%
  filter(row_number() %% 2 != 0) %>%
  mutate(percent_written = round(as.integer(out_reads)/as.integer(in_reads)*100, 1)) %>%
  arrange(-percent_written)

# Overwrite existing log
write.table(df, file = "./cutadapt_log.txt", sep = "\t",quote = FALSE, col.names = TRUE, row.names = FALSE)
```

Check that trimmed read lengths match expected lengths. Also check that forward and reverse reads are same lengths. *NOTE:* FIGARO requires forward reads to be the same length and reverse reads to be the same length, not necessarily that both forward and reverse reads are the same length. Since mehtaF/mehtaR are equal lengths, this is a special case where both reads should be the same length.
```{bash check trimmed read lengths}
# Extract max and min read lengths from all trimmed files
for f in `cat sample_names.txt`; do
  prinseq-lite.pl -fastq "$f"_R1_001_CUTADAPT.fastq -stats_len | grep 'max\|min' >> prinseq_log.txt
  prinseq-lite.pl -fastq "$f"_R2_001_CUTADAPT.fastq -stats_len | grep 'max\|min' >> prinseq_log.txt; done

# Check all read lengths are identical and match expected length
TRIMMED_LEN=$(cat prinseq_log.txt | cut -f3 | uniq)

if [ "$TRIMMED_LEN" == "$EXPECTED_LEN" ]; then
  echo "Success! Length of trimmed reads are identical and equal to specified length. Proceed to FIGARO."; else
  echo "Warning! Length of trimmed reads are not identical and/or not equal to specified length. Inspect cutadapt output before proceeding to FIGARO."; fi
  
# Move log files
mkdir ./log; mv *.txt ./log
```


# Step 2: Determine optimal quality-trimming positions for DADA2

Rename files as FIGARO requires.
```{bash rename files}
cd ../cutadapt

rename _CUTADAPT.fastq .fastq  *.fastq
rename DL13_OC17_ DL13-OC17- *.fastq && rename DL13_MOCK_ DL13-MOCK- *.fastq && rename DL13_BLAN_ DL13-BLAN- *.fastq
rename _EP \\-EP-CUTADAPT *.fastq
for file in *; do mv "$file" "$(echo "$file" | sed 's/\\//g')"; done
```

Run FIGARO requiring minimum overlap of 20 bp. -m set to 18 as workaround to primers being pre-trimmed and primer lengths cannot be set to 0. See [here](https://githubmemory.com/repo/Zymo-Research/figaro/issues/17).
```{bash run figaro}
# Make new directory
mkdir ../figaro; cd ../figaro

# Run FIGARO
figaro.py \
  -i ../cutadapt \
  -o ./ \
  -a 370 \
  -f 1 \
  -r 1 \
  -m 18
```